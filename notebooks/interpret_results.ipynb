{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference import evaluate_model\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from mltu.utils.text_utils import ctc_decoder, get_cer, get_wer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def interpret(model_path):\n",
    "    cer_val, wer_val = evaluate_model(\n",
    "    model_path=model_path, \n",
    "    datapath= model_path + '/val.csv' \n",
    "    )\n",
    "    cer_test, wer_test = evaluate_model(\n",
    "    model_path=model_path,\n",
    "    datapath='data/testset.npy'\n",
    "    )\n",
    "    print(\"\\t\\tCER\\t\\tWER\")\n",
    "    #round up to 4 decimal places \n",
    "    cer_val = round(cer_val, 4)\n",
    "    wer_val = round(wer_val, 4)\n",
    "    cer_test = round(cer_test, 4)\n",
    "    wer_test = round(wer_test, 4)\n",
    "    \n",
    "    print(f\"Validation\\t{cer_val}\\t\\t{wer_val}\")\n",
    "    print(f\"Test\\t\\t{cer_test}\\t\\t{wer_test}\")\n",
    "    \n",
    "    return (cer_val, wer_val, cer_test, wer_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTR NET  without the custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:10<00:00, 87.59it/s]\n",
      "100%|██████████| 247/247 [00:02<00:00, 99.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tCER\t\tWER\n",
      "Validation\t0.152\t\t0.29\n",
      "Test\t\t0.3601\t\t0.6073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "htr_net_no_cus = interpret('results/htr_net_no_custom_new_split')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTR NET with the custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1128/1128 [00:12<00:00, 90.37it/s]\n",
      "100%|██████████| 247/247 [00:02<00:00, 98.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tCER\t\tWER\n",
      "Validation\t0.091\t\t0.2004\n",
      "Test\t\t0.2021\t\t0.3846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "htr_net_cus = interpret('results/htr_full_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-BILSTM from mltu WITHOUT custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:05<00:00, 159.30it/s]\n",
      "100%|██████████| 247/247 [00:01<00:00, 186.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tCER\t\tWER\n",
      "Validation\t0.1581\t\t0.3033\n",
      "Test\t\t0.3559\t\t0.5506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_bilstm_no_cust = interpret('results/cnn_bilstm_no_custom')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-BILSTM from mltu WITH custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1128/1128 [00:06<00:00, 169.75it/s]\n",
      "100%|██████████| 247/247 [00:01<00:00, 184.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tCER\t\tWER\n",
      "Validation\t0.0948\t\t0.195\n",
      "Test\t\t0.1761\t\t0.3279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_bilstm_cust = interpret('results/cnn_bilstm_mltu_all_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t---------------- CER ----------------\n",
      "Custom dataset \t\t WITHOUT \t\t WITH\n",
      "\t\t\t Val \t Test \t\t Val \t Test\n",
      "CNN-BiLSTM-MLTU  \t0.1581 \t 0.3559 \t 0.0948  0.1761\n",
      "HTR-Net \t\t 0.152 \t 0.3601 \t 0.091 \t 0.2021\n",
      "\t\t\t---------------- WER ----------------\n",
      "Custom dataset \t\t WITHOUT \t\t WITH\n",
      "\t\t\t Val \t Test \t\t Val \t Test\n",
      "CNN-BiLSTM-MLTU  \t0.3033 \t 0.5506 \t 0.195\t 0.3279\n",
      "HTR-Net \t\t0.29 \t 0.6073 \t 0.2004  0.3846\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t\\t\\t---------------- CER ----------------\")\n",
    "print(\"Custom dataset \\t\\t WITHOUT \\t\\t WITH\")\n",
    "print(\"\\t\\t\\t Val \\t Test \\t\\t Val \\t Test\") \n",
    "print(f\"CNN-BiLSTM-MLTU  \\t{cnn_bilstm_no_cust[0]} \\t {cnn_bilstm_no_cust[2]} \\t {cnn_bilstm_cust[0]}  {cnn_bilstm_cust[2]}\")\n",
    "print(f\"HTR-Net \\t\\t {htr_net_no_cus[0]} \\t {htr_net_no_cus[2]} \\t {htr_net_cus[0]} \\t {htr_net_cus[2]}\")\n",
    "print(\"\\t\\t\\t---------------- WER ----------------\")\n",
    "print(\"Custom dataset \\t\\t WITHOUT \\t\\t WITH\")\n",
    "print(\"\\t\\t\\t Val \\t Test \\t\\t Val \\t Test\")\n",
    "print(f\"CNN-BiLSTM-MLTU  \\t{cnn_bilstm_no_cust[1]} \\t {cnn_bilstm_no_cust[3]} \\t {cnn_bilstm_cust[1]}\\t {cnn_bilstm_cust[3]}\")\n",
    "print(f\"HTR-Net \\t\\t{htr_net_no_cus[1]} \\t {htr_net_no_cus[3]} \\t {htr_net_cus[1]}  {htr_net_cus[3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "provided_preds_df = pd.read_csv('data/raw/chess_reader_data/prediciton.csv')\n",
    "# open test set \n",
    "def get_perf_of_third_party(third_party_col): \n",
    "    test_set = np.load('data/testset.npy', allow_pickle=True) \n",
    "    # preds = provided_preds_df[third_party_col].values\n",
    "    \n",
    "    avg_cer = 0 \n",
    "   \n",
    "    avg_wer = 0 \n",
    "    for (img_file_name,label) in test_set : \n",
    "        image_name = img_file_name.split('/')[-1] \n",
    "        # remove .png \n",
    "        image_id = image_name.split('.')[0] \n",
    "        # find rows that have image_name as their first column\n",
    "        rows = provided_preds_df.loc[provided_preds_df[\"id\"] == int(image_id)] \n",
    "        pred = str(rows[third_party_col].values[0]) \n",
    "        pred = pred if pred != 'nan' else '' \n",
    "        avg_cer += get_cer(label, pred)\n",
    "        avg_wer += get_wer(pred, label) \n",
    "    avg_cer= round(avg_cer / len(test_set), 4)\n",
    "    avg_wer = round(avg_wer / len(test_set), 4)\n",
    "    return avg_cer,avg_wer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_google, wer_google = get_perf_of_third_party('gl')\n",
    "cer_azure, wer_azure = get_perf_of_third_party('az') \n",
    "cer_abby, wer_azure = get_perf_of_third_party('ab')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Third Party OCR on Test Set ----------------\n",
      "\t\t  CER \t\t WER\n",
      "Google\t\t  0.2541 \t 0.4413\n",
      "Azure\t\t  0.2877 \t 0.3765\n",
      "Abbyy\t\t  0.2548 \t 0.3765\n",
      "----------------- Our Models on Test Set ----------------\n",
      "\t\t  CER \t\t WER\n",
      "CNN-BiLSTM-MLTU\t  0.1761 \t 0.3279\n",
      "HTR-Net\t\t  0.2021 \t 0.3846\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------- Third Party OCR on Test Set ----------------\")\n",
    "print(\"\\t\\t  CER \\t\\t WER\") \n",
    "print(f\"Google\\t\\t  {cer_google} \\t {wer_google}\")\n",
    "print(f\"Azure\\t\\t  {cer_azure} \\t {wer_azure}\")\n",
    "print(f\"Abbyy\\t\\t  {cer_abby} \\t {wer_azure}\")\n",
    "print(\"----------------- Our Models on Test Set ----------------\")\n",
    "print(\"\\t\\t  CER \\t\\t WER\") \n",
    "print(f\"CNN-BiLSTM-MLTU\\t  {cnn_bilstm_cust[2]} \\t {cnn_bilstm_cust[3]}\")\n",
    "print(f\"HTR-Net\\t\\t  {htr_net_cus[2]} \\t {htr_net_cus[3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs433-sofia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
